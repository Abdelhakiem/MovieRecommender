{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Movies Recommendation Using Content Based Filtering\n",
    "# Outline\n",
    "- [ 1- Packages](#1--importing-required-packages)\n",
    "- [ 2- Datasets](#2-importing-datasets)\n",
    "- [ 3- Preparing the data](#3--data-preperation)\n",
    "- [ 4- Neural Network](#4-neural-network-for-content-based-filtering)\n",
    "- [ Saving the model](#5--saving-trained-model)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1- Importing required packages."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-19T14:56:00.299865Z",
     "end_time": "2023-05-19T14:56:00.315212Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2-Importing datasets\n",
    "The data set is processed from the [MovieLens ml-latest-small](https://grouplens.org/datasets/movielens/latest/) dataset.\n",
    "The **movie dataset** provided to the network is a combination of the original data and some 'engineered features'. The original features are the year the movie was released and the movie's genre's presented as a one-hot vector. There are 14 genres. The engineered feature is an average rating derived from the user ratings.\n",
    "\n",
    "The **user content** is composed of engineered features. A per genre average rating is computed per user. Additionally, a user id, rating count and rating average are available but not included in the training or prediction content. They are carried with the data set because they are useful in interpreting data.\n",
    "The **y** dataset contains movies ratings."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "outputs": [
    {
     "data": {
      "text/plain": "   user id  rating count  rating ave  Action  Adventure  Animation  Children  \\\n0      2.0          22.0         4.0    3.95       4.25        0.0       0.0   \n1      2.0          22.0         4.0    3.95       4.25        0.0       0.0   \n2      2.0          22.0         4.0    3.95       4.25        0.0       0.0   \n3      2.0          22.0         4.0    3.95       4.25        0.0       0.0   \n4      2.0          22.0         4.0    3.95       4.25        0.0       0.0   \n\n   Comedy  Crime  Documentary  Drama  Fantasy  Horror  Mystery  Romance  \\\n0     4.0   4.12          4.0   4.04      0.0     3.0      4.0      0.0   \n1     4.0   4.12          4.0   4.04      0.0     3.0      4.0      0.0   \n2     4.0   4.12          4.0   4.04      0.0     3.0      4.0      0.0   \n3     4.0   4.12          4.0   4.04      0.0     3.0      4.0      0.0   \n4     4.0   4.12          4.0   4.04      0.0     3.0      4.0      0.0   \n\n   Sci-Fi  Thriller  \n0    3.88      3.89  \n1    3.88      3.89  \n2    3.88      3.89  \n3    3.88      3.89  \n4    3.88      3.89  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user id</th>\n      <th>rating count</th>\n      <th>rating ave</th>\n      <th>Action</th>\n      <th>Adventure</th>\n      <th>Animation</th>\n      <th>Children</th>\n      <th>Comedy</th>\n      <th>Crime</th>\n      <th>Documentary</th>\n      <th>Drama</th>\n      <th>Fantasy</th>\n      <th>Horror</th>\n      <th>Mystery</th>\n      <th>Romance</th>\n      <th>Sci-Fi</th>\n      <th>Thriller</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2.0</td>\n      <td>22.0</td>\n      <td>4.0</td>\n      <td>3.95</td>\n      <td>4.25</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>4.12</td>\n      <td>4.0</td>\n      <td>4.04</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>3.88</td>\n      <td>3.89</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2.0</td>\n      <td>22.0</td>\n      <td>4.0</td>\n      <td>3.95</td>\n      <td>4.25</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>4.12</td>\n      <td>4.0</td>\n      <td>4.04</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>3.88</td>\n      <td>3.89</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2.0</td>\n      <td>22.0</td>\n      <td>4.0</td>\n      <td>3.95</td>\n      <td>4.25</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>4.12</td>\n      <td>4.0</td>\n      <td>4.04</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>3.88</td>\n      <td>3.89</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2.0</td>\n      <td>22.0</td>\n      <td>4.0</td>\n      <td>3.95</td>\n      <td>4.25</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>4.12</td>\n      <td>4.0</td>\n      <td>4.04</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>3.88</td>\n      <td>3.89</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2.0</td>\n      <td>22.0</td>\n      <td>4.0</td>\n      <td>3.95</td>\n      <td>4.25</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>4.12</td>\n      <td>4.0</td>\n      <td>4.04</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>3.88</td>\n      <td>3.89</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_df=pd.read_csv('../input/users.csv')\n",
    "movie_df=pd.read_csv('../input/movies.csv')\n",
    "y=pd.read_csv('../input/ratings.csv')\n",
    "\n",
    "num_user_features = user_df.shape[1] - 3  # remove userid, rating count and ave rating during training\n",
    "num_item_features = movie_df.shape[1] - 1  # remove movie id at train time\n",
    "uvs = 3  # user genre vector start\n",
    "ivs = 3  # item genre vector start\n",
    "u_s = 3  # start of columns to use in training, user\n",
    "i_s = 1  # start of columns to use in training, items\n",
    "\n",
    "user_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-19T15:52:05.156651Z",
     "end_time": "2023-05-19T15:52:05.302899Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "outputs": [
    {
     "data": {
      "text/plain": "   movie id  year  ave rating  Action  Adventure  Animation  Children  Comedy  \\\n0      6874  2003    3.961832       1          0          0         0       0   \n1      8798  2004    3.761364       1          0          0         0       0   \n2     46970  2006    3.250000       1          0          0         0       1   \n3     48516  2006    4.252336       0          0          0         0       0   \n4     58559  2008    4.238255       1          0          0         0       0   \n\n   Crime  Documentary  Drama  Fantasy  Horror  Mystery  Romance  Sci-Fi  \\\n0      1            0      0        0       0        0        0       0   \n1      1            0      1        0       0        0        0       0   \n2      0            0      0        0       0        0        0       0   \n3      1            0      1        0       0        0        0       0   \n4      1            0      1        0       0        0        0       0   \n\n   Thriller  \n0         1  \n1         1  \n2         0  \n3         1  \n4         0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>movie id</th>\n      <th>year</th>\n      <th>ave rating</th>\n      <th>Action</th>\n      <th>Adventure</th>\n      <th>Animation</th>\n      <th>Children</th>\n      <th>Comedy</th>\n      <th>Crime</th>\n      <th>Documentary</th>\n      <th>Drama</th>\n      <th>Fantasy</th>\n      <th>Horror</th>\n      <th>Mystery</th>\n      <th>Romance</th>\n      <th>Sci-Fi</th>\n      <th>Thriller</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>6874</td>\n      <td>2003</td>\n      <td>3.961832</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>8798</td>\n      <td>2004</td>\n      <td>3.761364</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>46970</td>\n      <td>2006</td>\n      <td>3.250000</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>48516</td>\n      <td>2006</td>\n      <td>4.252336</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>58559</td>\n      <td>2008</td>\n      <td>4.238255</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-19T14:56:01.014978Z",
     "end_time": "2023-05-19T14:56:01.086500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [
    {
     "data": {
      "text/plain": "   rating\n0     4.0\n1     3.5\n2     4.0\n3     4.0\n4     4.5",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3.5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4.5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-19T14:56:01.221848Z",
     "end_time": "2023-05-19T14:56:01.347129Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3- Data Preperation\n",
    "Scalling the numerical features using StandardScaler.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "outputs": [],
   "source": [
    "user_df_unscaled=user_df.copy()\n",
    "movie_df_unscaled=movie_df.copy()\n",
    "y_unscaled=y.copy()\n",
    "user_df=np.array(user_df)\n",
    "movie_df=np.array(movie_df)\n",
    "y=np.array(y)\n",
    "\n",
    "user_scaler=StandardScaler()\n",
    "movie_scaler=StandardScaler()\n",
    "y_scaler=MinMaxScaler((-1,1))\n",
    "\n",
    "user_scaler.fit(user_df)\n",
    "movie_scaler.fit(movie_df)\n",
    "y_scaler.fit(np.array(y).reshape(-1,1))\n",
    "\n",
    "user_df=pd.DataFrame(user_scaler.transform(user_df),columns=user_df_unscaled.columns)\n",
    "movie_df=pd.DataFrame(movie_scaler.transform(movie_df),columns=movie_df_unscaled.columns)\n",
    "y=y_scaler.transform(y.reshape(-1,1))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-19T15:52:08.324319Z",
     "end_time": "2023-05-19T15:52:08.378070Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Splitting the datasets into training and testing data."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "outputs": [],
   "source": [
    "user_train,user_test=train_test_split(user_df,test_size=0.3,shuffle=True,random_state=123)\n",
    "movie_train,movie_test=train_test_split(movie_df,test_size=0.3,shuffle=True,random_state=123)\n",
    "y_train,y_test=train_test_split(y,test_size=0.3,shuffle=True,random_state=123)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-19T15:52:11.844224Z",
     "end_time": "2023-05-19T15:52:11.880896Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4-Neural Network for Content Based Filtering"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_10 (InputLayer)          [(None, 14)]         0           []                               \n",
      "                                                                                                  \n",
      " input_11 (InputLayer)          [(None, 16)]         0           []                               \n",
      "                                                                                                  \n",
      " sequential_14 (Sequential)     (None, 32)           40864       ['input_10[0][0]']               \n",
      "                                                                                                  \n",
      " sequential_15 (Sequential)     (None, 32)           41376       ['input_11[0][0]']               \n",
      "                                                                                                  \n",
      " tf.math.l2_normalize_8 (TFOpLa  (None, 32)          0           ['sequential_14[0][0]']          \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " tf.math.l2_normalize_9 (TFOpLa  (None, 32)          0           ['sequential_15[0][0]']          \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " dot_4 (Dot)                    (None, 1)            0           ['tf.math.l2_normalize_8[0][0]', \n",
      "                                                                  'tf.math.l2_normalize_9[0][0]'] \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 82,240\n",
      "Trainable params: 82,240\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# GRADED_CELL\n",
    "# UNQ_C1\n",
    "\n",
    "num_outputs = 32\n",
    "tf.random.set_seed(1)\n",
    "user_NN = tf.keras.models.Sequential([\n",
    "    ### START CODE HERE ###\n",
    "keras.layers.Dense(units=256,activation='relu'),\n",
    "  keras.layers.Dense(units=128,activation='relu'),\n",
    "  keras.layers.Dense(units=num_outputs,activation='linear')\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "])\n",
    "\n",
    "item_NN = tf.keras.models.Sequential([\n",
    "    ### START CODE HERE ###\n",
    "  keras.layers.Dense(units=256,activation='relu'),\n",
    "  keras.layers.Dense(units=128,activation='relu'),\n",
    "  keras.layers.Dense(units=num_outputs,activation='linear')\n",
    "    ### END CODE HERE ###\n",
    "])\n",
    "\n",
    "# create the user input and point to the base network\n",
    "input_user = keras.layers.Input(shape=(num_user_features))\n",
    "vu = user_NN(input_user)\n",
    "vu = tf.linalg.l2_normalize(vu, axis=1)\n",
    "\n",
    "# create the item input and point to the base network\n",
    "input_item = keras.layers.Input(shape=(num_item_features))\n",
    "vm = item_NN(input_item)\n",
    "vm = tf.linalg.l2_normalize(vm, axis=1)\n",
    "\n",
    "# compute the dot product of the two vectors vu and vm\n",
    "output = keras.layers.Dot(axes=1)([vu, vm])\n",
    "\n",
    "# specify the inputs and output of the model\n",
    "model = keras.Model([input_user, input_item], output)\n",
    "\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-19T15:52:14.625481Z",
     "end_time": "2023-05-19T15:52:14.747212Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "outputs": [],
   "source": [
    "tf.random.set_seed(1)\n",
    "cost_fn = keras.losses.MeanSquaredError()\n",
    "opt = keras.optimizers.Adam(learning_rate=0.01)\n",
    "model.compile(optimizer=opt,\n",
    "              loss=cost_fn)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-19T15:52:16.430630Z",
     "end_time": "2023-05-19T15:52:16.461570Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "outputs": [
    {
     "ename": "InvalidIndexError",
     "evalue": "(slice(None, None, None), slice(3, None, None))",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "File \u001B[1;32m~\\Desktop\\DataCamp\\venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key, method, tolerance)\u001B[0m\n\u001B[0;32m   3801\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 3802\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3803\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[1;32m~\\Desktop\\DataCamp\\venv\\lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m~\\Desktop\\DataCamp\\venv\\lib\\site-packages\\pandas\\_libs\\index.pyx:144\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mTypeError\u001B[0m: '(slice(None, None, None), slice(3, None, None))' is an invalid key",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mInvalidIndexError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[145], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m tf\u001B[38;5;241m.\u001B[39mrandom\u001B[38;5;241m.\u001B[39mset_seed(\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m----> 2\u001B[0m model\u001B[38;5;241m.\u001B[39mfit([\u001B[43muser_train\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mu_s\u001B[49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m, movie_train[:, i_s:]], y_train, epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m30\u001B[39m)\n",
      "File \u001B[1;32m~\\Desktop\\DataCamp\\venv\\lib\\site-packages\\pandas\\core\\frame.py:3807\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3805\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mnlevels \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m   3806\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_multilevel(key)\n\u001B[1;32m-> 3807\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3808\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[0;32m   3809\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m [indexer]\n",
      "File \u001B[1;32m~\\Desktop\\DataCamp\\venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3809\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key, method, tolerance)\u001B[0m\n\u001B[0;32m   3804\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[0;32m   3805\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[0;32m   3806\u001B[0m         \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[0;32m   3807\u001B[0m         \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[0;32m   3808\u001B[0m         \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[1;32m-> 3809\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_check_indexing_error\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3810\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m\n\u001B[0;32m   3812\u001B[0m \u001B[38;5;66;03m# GH#42269\u001B[39;00m\n",
      "File \u001B[1;32m~\\Desktop\\DataCamp\\venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5925\u001B[0m, in \u001B[0;36mIndex._check_indexing_error\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   5921\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_check_indexing_error\u001B[39m(\u001B[38;5;28mself\u001B[39m, key):\n\u001B[0;32m   5922\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_scalar(key):\n\u001B[0;32m   5923\u001B[0m         \u001B[38;5;66;03m# if key is not a scalar, directly raise an error (the code below\u001B[39;00m\n\u001B[0;32m   5924\u001B[0m         \u001B[38;5;66;03m# would convert to numpy arrays and raise later any way) - GH29926\u001B[39;00m\n\u001B[1;32m-> 5925\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m InvalidIndexError(key)\n",
      "\u001B[1;31mInvalidIndexError\u001B[0m: (slice(None, None, None), slice(3, None, None))"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "model.fit([user_train[:, u_s:], movie_train[:, i_s:]], y_train, epochs=30)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-19T14:56:03.350389Z",
     "end_time": "2023-05-19T14:57:05.087855Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "478/478 [==============================] - 1s 1ms/step - loss: 0.0830\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.08295433223247528"
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate([user_test[:, u_s:], movie_test[:, i_s:]], y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-19T14:57:05.089057Z",
     "end_time": "2023-05-19T14:57:05.909341Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 5- Saving trained models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/my_model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('../models/my_model')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-19T14:57:22.186024Z",
     "end_time": "2023-05-19T14:57:23.439703Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "outputs": [
    {
     "data": {
      "text/plain": "['../models/targetScaler.bin']"
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "dump(user_scaler,'../models/userScaler.bin',compress=True)\n",
    "dump(movie_scaler,'../models/movieScaler.bin',compress=True)\n",
    "dump(y_scaler,'../models/targetScaler.bin',compress=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-19T15:53:40.076343Z",
     "end_time": "2023-05-19T15:53:40.102201Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "new_user_id = 5000\n",
    "new_rating_ave = 0.0\n",
    "new_action = 0.0\n",
    "new_adventure = 5.0\n",
    "new_animation = 0.0\n",
    "new_childrens = 0.0\n",
    "new_comedy = 0.0\n",
    "new_crime = 0.0\n",
    "new_documentary = 0.0\n",
    "new_drama = 0.0\n",
    "new_fantasy = 5.0\n",
    "new_horror = 0.0\n",
    "new_mystery = 0.0\n",
    "new_romance = 0.0\n",
    "new_scifi = 0.0\n",
    "new_thriller = 0.0\n",
    "new_rating_count = 3\n",
    "\n",
    "user_vec = np.array([[new_user_id, new_rating_count, new_rating_ave,\n",
    "                      new_action, new_adventure, new_animation, new_childrens,\n",
    "                      new_comedy, new_crime, new_documentary,\n",
    "                      new_drama, new_fantasy, new_horror, new_mystery,\n",
    "                      new_romance, new_scifi, new_thriller]])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-19T14:11:52.925350Z",
     "end_time": "2023-05-19T14:11:52.942676Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "user_vec=pd.DataFrame(user_vec)\n",
    "user_vec=user_vec.loc[user_vec.index.repeat(5)]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-19T14:11:57.123032Z",
     "end_time": "2023-05-19T14:11:57.135678Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "user_vec.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-19T14:11:58.746140Z",
     "end_time": "2023-05-19T14:11:58.781812Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x=np.array([[1,23,4]])\n",
    "print(np.repeat(x,3,axis=0))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-19T14:34:56.778686Z",
     "end_time": "2023-05-19T14:34:56.787923Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
