{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Movies Recommendation Using Content Based Filtering\n",
    "# Outline\n",
    "- [ 1- Packages](#1--importing-required-packages)\n",
    "- [ 2- Datasets](#2-importing-datasets)\n",
    "- [ 3- Preparing the data](#3--data-preperation)\n",
    "- [ 4- Neural Network](#4-neural-network-for-content-based-filtering)\n",
    "- [ 5- Saving the model](#5--saving-trained-models)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1- Importing required packages."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-19T17:34:00.181485Z",
     "end_time": "2023-05-19T17:34:00.197013Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2-Importing datasets\n",
    "The data set is processed from the [MovieLens ml-latest-small](https://grouplens.org/datasets/movielens/latest/) dataset.\n",
    "The **movie dataset** provided to the network is a combination of the original data and some 'engineered features'. The original features are the year the movie was released and the movie's genre's presented as a one-hot vector. There are 14 genres. The engineered feature is an average rating derived from the user ratings.\n",
    "\n",
    "The **user content** is composed of engineered features. A per genre average rating is computed per user. Additionally, a user id, rating count and rating average are available but not included in the training or prediction content. They are carried with the data set because they are useful in interpreting data.\n",
    "The **y** dataset contains movies ratings."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "outputs": [
    {
     "data": {
      "text/plain": "   user id  rating count  rating ave  Action  Adventure  Animation  Children  \\\n0      2.0          22.0         4.0    3.95       4.25        0.0       0.0   \n1      2.0          22.0         4.0    3.95       4.25        0.0       0.0   \n2      2.0          22.0         4.0    3.95       4.25        0.0       0.0   \n3      2.0          22.0         4.0    3.95       4.25        0.0       0.0   \n4      2.0          22.0         4.0    3.95       4.25        0.0       0.0   \n\n   Comedy  Crime  Documentary  Drama  Fantasy  Horror  Mystery  Romance  \\\n0     4.0   4.12          4.0   4.04      0.0     3.0      4.0      0.0   \n1     4.0   4.12          4.0   4.04      0.0     3.0      4.0      0.0   \n2     4.0   4.12          4.0   4.04      0.0     3.0      4.0      0.0   \n3     4.0   4.12          4.0   4.04      0.0     3.0      4.0      0.0   \n4     4.0   4.12          4.0   4.04      0.0     3.0      4.0      0.0   \n\n   Sci-Fi  Thriller  \n0    3.88      3.89  \n1    3.88      3.89  \n2    3.88      3.89  \n3    3.88      3.89  \n4    3.88      3.89  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user id</th>\n      <th>rating count</th>\n      <th>rating ave</th>\n      <th>Action</th>\n      <th>Adventure</th>\n      <th>Animation</th>\n      <th>Children</th>\n      <th>Comedy</th>\n      <th>Crime</th>\n      <th>Documentary</th>\n      <th>Drama</th>\n      <th>Fantasy</th>\n      <th>Horror</th>\n      <th>Mystery</th>\n      <th>Romance</th>\n      <th>Sci-Fi</th>\n      <th>Thriller</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2.0</td>\n      <td>22.0</td>\n      <td>4.0</td>\n      <td>3.95</td>\n      <td>4.25</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>4.12</td>\n      <td>4.0</td>\n      <td>4.04</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>3.88</td>\n      <td>3.89</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2.0</td>\n      <td>22.0</td>\n      <td>4.0</td>\n      <td>3.95</td>\n      <td>4.25</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>4.12</td>\n      <td>4.0</td>\n      <td>4.04</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>3.88</td>\n      <td>3.89</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2.0</td>\n      <td>22.0</td>\n      <td>4.0</td>\n      <td>3.95</td>\n      <td>4.25</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>4.12</td>\n      <td>4.0</td>\n      <td>4.04</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>3.88</td>\n      <td>3.89</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2.0</td>\n      <td>22.0</td>\n      <td>4.0</td>\n      <td>3.95</td>\n      <td>4.25</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>4.12</td>\n      <td>4.0</td>\n      <td>4.04</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>3.88</td>\n      <td>3.89</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2.0</td>\n      <td>22.0</td>\n      <td>4.0</td>\n      <td>3.95</td>\n      <td>4.25</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>4.12</td>\n      <td>4.0</td>\n      <td>4.04</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>3.88</td>\n      <td>3.89</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_df=pd.read_csv('../input/users.csv')\n",
    "movie_df=pd.read_csv('../input/movies.csv')\n",
    "y=pd.read_csv('../input/ratings.csv')\n",
    "\n",
    "num_user_features = user_df.shape[1] - 3  # remove userid, rating count and ave rating during training\n",
    "num_item_features = movie_df.shape[1] - 1  # remove movie id at train time\n",
    "uvs = 3  # user genre vector start\n",
    "ivs = 3  # item genre vector start\n",
    "u_s = 3  # start of columns to use in training, user\n",
    "i_s = 1  # start of columns to use in training, items\n",
    "\n",
    "user_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-19T17:34:01.551891Z",
     "end_time": "2023-05-19T17:34:01.754437Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "outputs": [
    {
     "data": {
      "text/plain": "   movie id  year  ave rating  Action  Adventure  Animation  Children  Comedy  \\\n0      6874  2003    3.961832       1          0          0         0       0   \n1      8798  2004    3.761364       1          0          0         0       0   \n2     46970  2006    3.250000       1          0          0         0       1   \n3     48516  2006    4.252336       0          0          0         0       0   \n4     58559  2008    4.238255       1          0          0         0       0   \n\n   Crime  Documentary  Drama  Fantasy  Horror  Mystery  Romance  Sci-Fi  \\\n0      1            0      0        0       0        0        0       0   \n1      1            0      1        0       0        0        0       0   \n2      0            0      0        0       0        0        0       0   \n3      1            0      1        0       0        0        0       0   \n4      1            0      1        0       0        0        0       0   \n\n   Thriller  \n0         1  \n1         1  \n2         0  \n3         1  \n4         0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>movie id</th>\n      <th>year</th>\n      <th>ave rating</th>\n      <th>Action</th>\n      <th>Adventure</th>\n      <th>Animation</th>\n      <th>Children</th>\n      <th>Comedy</th>\n      <th>Crime</th>\n      <th>Documentary</th>\n      <th>Drama</th>\n      <th>Fantasy</th>\n      <th>Horror</th>\n      <th>Mystery</th>\n      <th>Romance</th>\n      <th>Sci-Fi</th>\n      <th>Thriller</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>6874</td>\n      <td>2003</td>\n      <td>3.961832</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>8798</td>\n      <td>2004</td>\n      <td>3.761364</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>46970</td>\n      <td>2006</td>\n      <td>3.250000</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>48516</td>\n      <td>2006</td>\n      <td>4.252336</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>58559</td>\n      <td>2008</td>\n      <td>4.238255</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-19T17:34:02.542482Z",
     "end_time": "2023-05-19T17:34:02.557442Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "outputs": [
    {
     "data": {
      "text/plain": "   rating\n0     4.0\n1     3.5\n2     4.0\n3     4.0\n4     4.5",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3.5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4.5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-19T17:34:03.352729Z",
     "end_time": "2023-05-19T17:34:03.373834Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3- Data Preperation\n",
    "Scalling the numerical features using StandardScaler.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "outputs": [],
   "source": [
    "user_df_unscaled=user_df.copy()\n",
    "movie_df_unscaled=movie_df.copy()\n",
    "y_unscaled=y.copy()\n",
    "user_df=np.array(user_df)\n",
    "movie_df=np.array(movie_df)\n",
    "y=np.array(y)\n",
    "\n",
    "user_scaler=StandardScaler()\n",
    "movie_scaler=StandardScaler()\n",
    "y_scaler=MinMaxScaler((-1,1))\n",
    "\n",
    "user_scaler.fit(user_df)\n",
    "movie_scaler.fit(movie_df)\n",
    "y_scaler.fit(np.array(y).reshape(-1,1))\n",
    "\n",
    "user_df=pd.DataFrame(user_scaler.transform(user_df),columns=user_df_unscaled.columns)\n",
    "movie_df=pd.DataFrame(movie_scaler.transform(movie_df),columns=movie_df_unscaled.columns)\n",
    "y=y_scaler.transform(y.reshape(-1,1))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-19T17:34:04.940124Z",
     "end_time": "2023-05-19T17:34:04.985105Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Splitting the datasets into training and testing data."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "outputs": [],
   "source": [
    "user_train,user_test=train_test_split(user_df,test_size=0.3,shuffle=True,random_state=123)\n",
    "movie_train,movie_test=train_test_split(movie_df,test_size=0.3,shuffle=True,random_state=123)\n",
    "y_train,y_test=train_test_split(y,test_size=0.3,shuffle=True,random_state=123)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-19T17:34:06.312006Z",
     "end_time": "2023-05-19T17:34:06.373858Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4-Neural Network for Content Based Filtering"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_12 (InputLayer)          [(None, 14)]         0           []                               \n",
      "                                                                                                  \n",
      " input_13 (InputLayer)          [(None, 16)]         0           []                               \n",
      "                                                                                                  \n",
      " sequential_16 (Sequential)     (None, 32)           40864       ['input_12[0][0]']               \n",
      "                                                                                                  \n",
      " sequential_17 (Sequential)     (None, 32)           41376       ['input_13[0][0]']               \n",
      "                                                                                                  \n",
      " tf.math.l2_normalize_10 (TFOpL  (None, 32)          0           ['sequential_16[0][0]']          \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.math.l2_normalize_11 (TFOpL  (None, 32)          0           ['sequential_17[0][0]']          \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " dot_5 (Dot)                    (None, 1)            0           ['tf.math.l2_normalize_10[0][0]',\n",
      "                                                                  'tf.math.l2_normalize_11[0][0]']\n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 82,240\n",
      "Trainable params: 82,240\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# GRADED_CELL\n",
    "# UNQ_C1\n",
    "\n",
    "num_outputs = 32\n",
    "tf.random.set_seed(1)\n",
    "user_NN = tf.keras.models.Sequential([\n",
    "    ### START CODE HERE ###\n",
    "keras.layers.Dense(units=256,activation='relu'),\n",
    "  keras.layers.Dense(units=128,activation='relu'),\n",
    "  keras.layers.Dense(units=num_outputs,activation='linear')\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "])\n",
    "\n",
    "item_NN = tf.keras.models.Sequential([\n",
    "    ### START CODE HERE ###\n",
    "  keras.layers.Dense(units=256,activation='relu'),\n",
    "  keras.layers.Dense(units=128,activation='relu'),\n",
    "  keras.layers.Dense(units=num_outputs,activation='linear')\n",
    "    ### END CODE HERE ###\n",
    "])\n",
    "\n",
    "# create the user input and point to the base network\n",
    "input_user = keras.layers.Input(shape=(num_user_features))\n",
    "vu = user_NN(input_user)\n",
    "vu = tf.linalg.l2_normalize(vu, axis=1)\n",
    "\n",
    "# create the item input and point to the base network\n",
    "input_item = keras.layers.Input(shape=(num_item_features))\n",
    "vm = item_NN(input_item)\n",
    "vm = tf.linalg.l2_normalize(vm, axis=1)\n",
    "\n",
    "# compute the dot product of the two vectors vu and vm\n",
    "output = keras.layers.Dot(axes=1)([vu, vm])\n",
    "\n",
    "# specify the inputs and output of the model\n",
    "model = keras.Model([input_user, input_item], output)\n",
    "\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-19T17:34:07.907712Z",
     "end_time": "2023-05-19T17:34:08.150150Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "outputs": [],
   "source": [
    "tf.random.set_seed(1)\n",
    "cost_fn = keras.losses.MeanSquaredError()\n",
    "opt = keras.optimizers.Adam(learning_rate=0.01)\n",
    "model.compile(optimizer=opt,\n",
    "              loss=cost_fn)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-19T17:34:09.542445Z",
     "end_time": "2023-05-19T17:34:09.572019Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1114/1114 [==============================] - 3s 2ms/step - loss: 0.1218\n",
      "Epoch 2/30\n",
      "1114/1114 [==============================] - 2s 2ms/step - loss: 0.1115\n",
      "Epoch 3/30\n",
      "1114/1114 [==============================] - 2s 2ms/step - loss: 0.1069\n",
      "Epoch 4/30\n",
      "1114/1114 [==============================] - 2s 2ms/step - loss: 0.1042\n",
      "Epoch 5/30\n",
      "1114/1114 [==============================] - 2s 2ms/step - loss: 0.1016\n",
      "Epoch 6/30\n",
      "1114/1114 [==============================] - 2s 2ms/step - loss: 0.0990\n",
      "Epoch 7/30\n",
      "1114/1114 [==============================] - 2s 2ms/step - loss: 0.0964\n",
      "Epoch 8/30\n",
      "1114/1114 [==============================] - 2s 2ms/step - loss: 0.0938\n",
      "Epoch 9/30\n",
      "1114/1114 [==============================] - 2s 2ms/step - loss: 0.0921\n",
      "Epoch 10/30\n",
      "1114/1114 [==============================] - 2s 2ms/step - loss: 0.0903\n",
      "Epoch 11/30\n",
      "1114/1114 [==============================] - 2s 2ms/step - loss: 0.0887\n",
      "Epoch 12/30\n",
      "1114/1114 [==============================] - 2s 2ms/step - loss: 0.0872\n",
      "Epoch 13/30\n",
      "1114/1114 [==============================] - 2s 2ms/step - loss: 0.0853\n",
      "Epoch 14/30\n",
      "1114/1114 [==============================] - 2s 2ms/step - loss: 0.0841\n",
      "Epoch 15/30\n",
      "1114/1114 [==============================] - 2s 2ms/step - loss: 0.0826\n",
      "Epoch 16/30\n",
      "1114/1114 [==============================] - 2s 2ms/step - loss: 0.0816\n",
      "Epoch 17/30\n",
      "1114/1114 [==============================] - 2s 2ms/step - loss: 0.0803\n",
      "Epoch 18/30\n",
      "1114/1114 [==============================] - 2s 2ms/step - loss: 0.0792\n",
      "Epoch 19/30\n",
      "1114/1114 [==============================] - 2s 2ms/step - loss: 0.0784\n",
      "Epoch 20/30\n",
      "1114/1114 [==============================] - 2s 2ms/step - loss: 0.0773\n",
      "Epoch 21/30\n",
      "1114/1114 [==============================] - 2s 2ms/step - loss: 0.0767\n",
      "Epoch 22/30\n",
      "1114/1114 [==============================] - 2s 2ms/step - loss: 0.0757\n",
      "Epoch 23/30\n",
      "1114/1114 [==============================] - 2s 2ms/step - loss: 0.0750\n",
      "Epoch 24/30\n",
      "1114/1114 [==============================] - 2s 2ms/step - loss: 0.0745\n",
      "Epoch 25/30\n",
      "1114/1114 [==============================] - 2s 2ms/step - loss: 0.0735\n",
      "Epoch 26/30\n",
      "1114/1114 [==============================] - 2s 2ms/step - loss: 0.0730\n",
      "Epoch 27/30\n",
      "1114/1114 [==============================] - 2s 2ms/step - loss: 0.0722\n",
      "Epoch 28/30\n",
      "1114/1114 [==============================] - 2s 2ms/step - loss: 0.0716\n",
      "Epoch 29/30\n",
      "1114/1114 [==============================] - 2s 2ms/step - loss: 0.0710\n",
      "Epoch 30/30\n",
      "1114/1114 [==============================] - 2s 2ms/step - loss: 0.0703\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x1c3df70aca0>"
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "model.fit([user_train.iloc[:, u_s:], movie_train.iloc[:, i_s:]], y_train, epochs=30)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-19T17:35:55.508293Z",
     "end_time": "2023-05-19T17:36:55.467287Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "478/478 [==============================] - 1s 1ms/step - loss: 0.0830\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.08297690004110336"
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate([user_test.iloc[:, u_s:], movie_test.iloc[:, i_s:]], y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-19T17:37:33.028574Z",
     "end_time": "2023-05-19T17:37:33.848725Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 5- Saving trained models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/my_model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('../models/my_model')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-19T17:37:36.888051Z",
     "end_time": "2023-05-19T17:37:37.997874Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "outputs": [
    {
     "data": {
      "text/plain": "['../models/targetScaler.bin']"
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "dump(user_scaler,'../models/userScaler.bin',compress=True)\n",
    "dump(movie_scaler,'../models/movieScaler.bin',compress=True)\n",
    "dump(y_scaler,'../models/targetScaler.bin',compress=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-19T17:37:40.406679Z",
     "end_time": "2023-05-19T17:37:40.451559Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
